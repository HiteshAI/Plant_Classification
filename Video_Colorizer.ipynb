{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Colorizer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiteshAI/Projects/blob/master/Video_Colorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDW45-QN2TKE",
        "colab_type": "text"
      },
      "source": [
        "# **Video Colorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "00_GcC_trpdE",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-T-svuHytJ-8",
        "outputId": "37453d4a-fac9-41da-c394-a0351f3d9c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/jantic/DeOldify.git DeOldify"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeOldify'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/23)\u001b[K\rremote: Counting objects:   8% (2/23)\u001b[K\rremote: Counting objects:  13% (3/23)\u001b[K\rremote: Counting objects:  17% (4/23)\u001b[K\rremote: Counting objects:  21% (5/23)\u001b[K\rremote: Counting objects:  26% (6/23)\u001b[K\rremote: Counting objects:  30% (7/23)\u001b[K\rremote: Counting objects:  34% (8/23)\u001b[K\rremote: Counting objects:  39% (9/23)\u001b[K\rremote: Counting objects:  43% (10/23)\u001b[K\rremote: Counting objects:  47% (11/23)\u001b[K\rremote: Counting objects:  52% (12/23)\u001b[K\rremote: Counting objects:  56% (13/23)\u001b[K\rremote: Counting objects:  60% (14/23)\u001b[K\rremote: Counting objects:  65% (15/23)\u001b[K\rremote: Counting objects:  69% (16/23)\u001b[K\rremote: Counting objects:  73% (17/23)\u001b[K\rremote: Counting objects:  78% (18/23)\u001b[K\rremote: Counting objects:  82% (19/23)\u001b[K\rremote: Counting objects:  86% (20/23)\u001b[K\rremote: Counting objects:  91% (21/23)\u001b[K\rremote: Counting objects:  95% (22/23)\u001b[K\rremote: Counting objects: 100% (23/23)\u001b[K\rremote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 1921 (delta 5), reused 15 (delta 3), pack-reused 1898\u001b[K\n",
            "Receiving objects: 100% (1921/1921), 69.28 MiB | 30.47 MiB/s, done.\n",
            "Resolving deltas: 100% (828/828), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95qC_BlQk_Xk",
        "colab_type": "code",
        "outputId": "e8317532-77d1-4813-fb81-738f8811b27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd DeOldify"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeOldify\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lsx7xCXNSVt6",
        "outputId": "751a7c6c-c8ae-4c03-e0b6-7ea754c748f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==1.0.51\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/cc/dcc702cf43bb8c908d172e5be156615928f962366a20834c320cbca2b9d0/fastai-1.0.51-py3-none-any.whl (214kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 3.3MB/s \n",
            "\u001b[?25hCollecting tensorboardX==1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.8MB/s \n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Collecting ffmpeg-python==0.1.17\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/10/330cbc8e63d072d40413f4d470444a6a1e8c8c6a80b2a4ac302d1252ca1b/ffmpeg_python-0.1.17-py3-none-any.whl\n",
            "Collecting youtube-dl>=2019.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f6/c36b2e8dd3fd528e4b10f4061ff97e086448ae248df243e34b9019bc6a50/youtube_dl-2019.11.5-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 41.2MB/s \n",
            "\u001b[?25hCollecting jupyterlab\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/96/5629fec605f0d320f3857241e84704e533ee54eb2aa87c0b69c34bbcc3f2/jupyterlab-1.2.1-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3.3.0.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.4.7.28)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (4.3.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (0.1.21)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (7.352.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (0.25.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (1.3.0+cu100)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (19.2)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (3.6.6)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (1.17.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (0.4.1+cu100)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (2.21.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.6->-r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.6->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python==0.1.17->-r requirements.txt (line 4)) (0.16.0)\n",
            "Collecting jupyterlab-server~=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/98/5b87b9d38176bd98f23b58a8fb730e5124618d68571a011abbd38ad4a842/jupyterlab_server-1.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r requirements.txt (line 6)) (2.10.3)\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r requirements.txt (line 6)) (5.2.2)\n",
            "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r requirements.txt (line 6)) (4.5.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->-r requirements.txt (line 8)) (0.46)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.51->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.51->-r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.51->-r requirements.txt (line 1)) (2.4.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r requirements.txt (line 1)) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.6->-r requirements.txt (line 2)) (41.4.0)\n",
            "Collecting json5\n",
            "  Downloading https://files.pythonhosted.org/packages/30/44/062543d4a6718f99d82e5ecf9140dbdee8a03122f2c34fbd0b0609891707/json5-0.8.5-py2.py3-none-any.whl\n",
            "Collecting jsonschema>=3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/6c/888d7c3c1fce3974c88a01a6bc553528c99d3586e098eee23e8383dd11c3/jsonschema-3.1.1-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10->jupyterlab->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.6.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.8.2)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.3.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai==1.0.51->-r requirements.txt (line 1)) (4.28.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab->-r requirements.txt (line 6)) (0.23)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab->-r requirements.txt (line 6)) (19.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab->-r requirements.txt (line 6)) (0.15.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.4.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab->-r requirements.txt (line 6)) (7.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r requirements.txt (line 6)) (0.1.7)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-cp36-none-any.whl size=6085 sha256=09803bdb82d90f8c5f586fe72598e88baa322f69078cd8d07d4e9b0403c96151\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: fastai, tensorboardX, ffmpeg, ffmpeg-python, youtube-dl, json5, jsonschema, jupyterlab-server, jupyterlab\n",
            "  Found existing installation: fastai 1.0.59\n",
            "    Uninstalling fastai-1.0.59:\n",
            "      Successfully uninstalled fastai-1.0.59\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "Successfully installed fastai-1.0.51 ffmpeg-1.4 ffmpeg-python-0.1.17 json5-0.8.5 jsonschema-3.1.1 jupyterlab-1.2.1 jupyterlab-server-1.0.6 tensorboardX-1.6 youtube-dl-2019.11.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MsJa69CMwj3l",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "from pathlib import Path\n",
        "torch.backends.cudnn.benchmark=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEPuTUqk_Yd",
        "colab_type": "code",
        "outputId": "f4e8abd5-1854-4c2e-cfab-e41b81ca9571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "!mkdir 'models'\n",
        "!wget https://www.dropbox.com/s/336vn9y4qwyg9yz/ColorizeVideo_gen.pth?dl=0 -O ./models/ColorizeVideo_gen.pth"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-07 15:53:11--  https://www.dropbox.com/s/336vn9y4qwyg9yz/ColorizeVideo_gen.pth?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/336vn9y4qwyg9yz/ColorizeVideo_gen.pth [following]\n",
            "--2019-11-07 15:53:11--  https://www.dropbox.com/s/raw/336vn9y4qwyg9yz/ColorizeVideo_gen.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc910e16341efc9282133af2b984.dl.dropboxusercontent.com/cd/0/inline/Ar5ILTPFm3WUylv40Nc9tnZ77NlmAbxQIHI4xAkId9mOKVnv8QcYp0C3glJPcTN9T-qR4a0Cfe_eNxoy_gHbmOni70XfPI2MVMQeriUKemlcug/file# [following]\n",
            "--2019-11-07 15:53:12--  https://uc910e16341efc9282133af2b984.dl.dropboxusercontent.com/cd/0/inline/Ar5ILTPFm3WUylv40Nc9tnZ77NlmAbxQIHI4xAkId9mOKVnv8QcYp0C3glJPcTN9T-qR4a0Cfe_eNxoy_gHbmOni70XfPI2MVMQeriUKemlcug/file\n",
            "Resolving uc910e16341efc9282133af2b984.dl.dropboxusercontent.com (uc910e16341efc9282133af2b984.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc910e16341efc9282133af2b984.dl.dropboxusercontent.com (uc910e16341efc9282133af2b984.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Ar6aN0dygKi-0tgXnRrG9GzpJWR0AtqSMHXpCgSkNsKeTYU_Vr0rj0UopWqbtgQz-kowAnzLsAcIRK3rQ_Rgd2tCnyljSKgxYpnuOVQM93Qk7AU3t0nUHEfFp1xf3q4GqefMCI7kdCrX87LDgUFZMMoG21RNvfnR_ssH7aR4EmHv5oBxluTzbLILFr5whvmNlqV8XwOX29LhgnpQ8MBlA1KGD1rXhxuEu6fGEhlxq2u4xKhTmPD1-98MNuokUpDJOPkYtW2EEdrbmaqaDeIwOhJWiv2V3Gcg-p9x4Z2wpeV8smHsDCcuFkj7Zkonec86Vgn-Kmfb1F-vN2RzX3g1T6zm/file [following]\n",
            "--2019-11-07 15:53:12--  https://uc910e16341efc9282133af2b984.dl.dropboxusercontent.com/cd/0/inline2/Ar6aN0dygKi-0tgXnRrG9GzpJWR0AtqSMHXpCgSkNsKeTYU_Vr0rj0UopWqbtgQz-kowAnzLsAcIRK3rQ_Rgd2tCnyljSKgxYpnuOVQM93Qk7AU3t0nUHEfFp1xf3q4GqefMCI7kdCrX87LDgUFZMMoG21RNvfnR_ssH7aR4EmHv5oBxluTzbLILFr5whvmNlqV8XwOX29LhgnpQ8MBlA1KGD1rXhxuEu6fGEhlxq2u4xKhTmPD1-98MNuokUpDJOPkYtW2EEdrbmaqaDeIwOhJWiv2V3Gcg-p9x4Z2wpeV8smHsDCcuFkj7Zkonec86Vgn-Kmfb1F-vN2RzX3g1T6zm/file\n",
            "Reusing existing connection to uc910e16341efc9282133af2b984.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874066230 (834M) [application/octet-stream]\n",
            "Saving to: ‘./models/ColorizeVideo_gen.pth’\n",
            "\n",
            "./models/ColorizeVi 100%[===================>] 833.57M  35.9MB/s    in 23s     \n",
            "\n",
            "2019-11-07 15:53:36 (36.5 MB/s) - ‘./models/ColorizeVideo_gen.pth’ saved [874066230/874066230]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzHVnegp21hC",
        "outputId": "c4c49762-3796-4bad-db87-046456dfd324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "colorizer = get_video_colorizer()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/data_block.py:442: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
            "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
            "/usr/local/lib/python3.6/dist-packages/fastai/data_block.py:445: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
            "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
            "  or pass `ignore_empty=True` when labelling to remove this warning.\"\"\")\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 170M/170M [00:01<00:00, 90.5MB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PixelShuffle. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReplicationPad2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ParameterModule. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MergeLayer. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SigmoidRange. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DynamicUnetWide. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type UnetBlockWide. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CustomPixelShuffle_ICNR. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SelfAttention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PixelShuffle_ICNR. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SequentialEx. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pmY4j8fk_ZH",
        "colab_type": "code",
        "outputId": "679e3c03-10f3-4b60-cb57-f22d3a92e9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "source_url = 'https://www.youtube.com/watch?v=CoGxlhsTKxU' #@param {type:\"string\"}\n",
        "render_factor = 11  #@param {type: \"slider\", min: 5, max: 44}\n",
        "\n",
        "if source_url is not None and source_url !='':\n",
        "    video_path = colorizer.colorize_from_url(source_url, 'video.mp4', render_factor)\n",
        "    show_video_in_notebook(video_path)\n",
        "else:\n",
        "    print('Provide a video url and try again.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[youtube] CoGxlhsTKxU: Downloading webpage\n",
            "[youtube] CoGxlhsTKxU: Downloading video info webpage\n",
            "[download] Destination: video/source/video.f134.mp4\n",
            "[download] 100% of 8.64MiB in 00:00\n",
            "[download] Destination: video/source/video.mp4.f140\n",
            "[download] 100% of 3.29MiB in 00:00\n",
            "[ffmpeg] Merging formats into \"video/source/video.mp4\"\n",
            "Deleting original file video/source/video.f134.mp4 (pass -k to keep)\n",
            "Deleting original file video/source/video.mp4.f140 (pass -k to keep)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2311' class='' max='6510', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      35.50% [2311/6510 07:04<12:51]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjkfXRSpk_ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10,45,2):\n",
        "    colorizer.vis.plot_transformed_image('video/bwframes/video/00001.jpg', render_factor=i, display_render_factor=True, figsize=(8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJQQwd1TzxDO",
        "colab_type": "text"
      },
      "source": [
        "# **Super Resolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlz3QNWV1Sqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# import fastai\n",
        "# from fastai.vision import *\n",
        "# from fastai.callbacks import *\n",
        "# from fastai.utils.mem import *\n",
        "\n",
        "\n",
        "\n",
        "# from torchvision.models import vgg16_bn\n",
        "\n",
        "\n",
        "\n",
        "# torch.cuda.set_device(0)\n",
        "\n",
        "\n",
        "\n",
        "# path = Path('data/imagenet')\n",
        "# path_hr = path/'train'\n",
        "# path_lr = path/'small-64/train'\n",
        "# path_mr = path/'small-256/train'\n",
        "\n",
        "# # note: this notebook relies on models created by lesson7-superres.ipynb\n",
        "# path_pets = untar_data(URLs.PETS)\n",
        "\n",
        "\n",
        "\n",
        "# il = ImageList.from_folder(path_hr)\n",
        "\n",
        "\n",
        "\n",
        "# def resize_one(fn, i, path, size):\n",
        "#     dest = path/fn.relative_to(path_hr)\n",
        "#     dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "#     img = PIL.Image.open(fn)\n",
        "#     targ_sz = resize_to(img, size, use_min=True)\n",
        "#     img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
        "#     img.save(dest, quality=60)\n",
        "\n",
        "\n",
        "\n",
        "# assert path.exists(), f\"need imagenet dataset @ {path}\"\n",
        "# # create smaller image sets the first time this nb is run\n",
        "# sets = [(path_lr, 64), (path_mr, 256)]\n",
        "# for p,size in sets:\n",
        "#     if not p.exists(): \n",
        "#         print(f\"resizing to {size} into {p}\")\n",
        "#         parallel(partial(resize_one, path=p, size=size), il.items)\n",
        "\n",
        "\n",
        "\n",
        "# free = gpu_mem_get_free_no_cache()\n",
        "# # the max size of the test image depends on the available GPU RAM \n",
        "# if free > 8200: bs,size=16,256  \n",
        "# else:           bs,size=8,256\n",
        "# print(f\"using bs={bs}, size={size}, have {free}MB of GPU RAM free\")\n",
        "\n",
        "# arch = models.resnet34\n",
        "# # sample = 0.1\n",
        "# sample = False\n",
        "\n",
        "# tfms = get_transforms()\n",
        "\n",
        "# using bs=8, size=256, have 8109MB of GPU RAM free\n",
        "\n",
        "\n",
        "\n",
        "# src = ImageImageList.from_folder(path_lr)\n",
        "\n",
        "\n",
        "\n",
        "# if sample: src = src.filter_by_rand(sample, seed=42)\n",
        "\n",
        "\n",
        "\n",
        "# src = src.split_by_rand_pct(0.1, seed=42)\n",
        "\n",
        "\n",
        "\n",
        "# def get_data(bs,size):\n",
        "#     data = (src.label_from_func(lambda x: path_hr/x.relative_to(path_lr))\n",
        "#            .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
        "#            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
        "\n",
        "#     data.c = 3\n",
        "#     return data\n",
        "\n",
        "\n",
        "\n",
        "# data = get_data(bs,size)\n",
        "\n",
        "# Feature loss\n",
        "\n",
        "\n",
        "# def gram_matrix(x):\n",
        "#     n,c,h,w = x.size()\n",
        "#     x = x.view(n, c, -1)\n",
        "#     return (x @ x.transpose(1,2))/(c*h*w)\n",
        "\n",
        "\n",
        "\n",
        "# vgg_m = vgg16_bn(True).features.cuda().eval()\n",
        "# requires_grad(vgg_m, False)\n",
        "# blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
        "\n",
        "\n",
        "\n",
        "# base_loss = F.l1_loss\n",
        "\n",
        "# class FeatureLoss(nn.Module):\n",
        "#     def __init__(self, m_feat, layer_ids, layer_wgts):\n",
        "#         super().__init__()\n",
        "#         self.m_feat = m_feat\n",
        "#         self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "#         self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "#         self.wgts = layer_wgts\n",
        "#         self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "#               ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "#     def make_features(self, x, clone=False):\n",
        "#         self.m_feat(x)\n",
        "#         return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "    \n",
        "#     def forward(self, input, target):\n",
        "#         out_feat = self.make_features(target, clone=True)\n",
        "#         in_feat = self.make_features(input)\n",
        "#         self.feat_losses = [base_loss(input,target)]\n",
        "#         self.feat_losses += [base_loss(f_in, f_out)*w\n",
        "#                              for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "#         self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "#                              for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "#         self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "#         return sum(self.feat_losses)\n",
        "    \n",
        "#     def __del__(self): self.hooks.remove()\n",
        "\n",
        "\n",
        "\n",
        "# feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])\n",
        "\n",
        "# wd = 1e-3\n",
        "# learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight)\n",
        "# gc.collect();\n",
        "\n",
        "\n",
        "\n",
        "# learn.unfreeze()\n",
        "\n",
        "\n",
        "\n",
        "# # relies on first running lesson7-superres.ipynb which created the following model\n",
        "# learn.load((path_pets/'small-96'/'models'/'2b').absolute());\n",
        "\n",
        "\n",
        "\n",
        "# learn.fit_one_cycle(1, slice(1e-6,1e-4))\n",
        "\n",
        "# learn.save('imagenet')\n",
        "\n",
        "\n",
        "\n",
        "# learn.show_results(rows=3, imgsize=5)\n",
        "\n",
        "\n",
        "\n",
        "# learn.recorder.plot_losses()\n",
        "\n",
        "\n",
        "\n",
        "# _=learn.load('imagenet')\n",
        "\n",
        "\n",
        "\n",
        "# data_mr = (ImageImageList.from_folder(path_mr).split_by_rand_pct(0.1, seed=42)\n",
        "#           .label_from_func(lambda x: path_hr/x.relative_to(path_mr))\n",
        "#           .transform(get_transforms(), size=(820,1024), tfm_y=True)\n",
        "#           .databunch(bs=2).normalize(imagenet_stats, do_y=True))\n",
        "\n",
        "\n",
        "\n",
        "# learn.data = data_mr\n",
        "\n",
        "\n",
        "\n",
        "# # here put some image you want to enhance, e.g. the original notebook uses a single video frame from a powerpoint presentation on dropout paper\n",
        "# fn = path_pets/'other'/'dropout.jpg'\n",
        "\n",
        "\n",
        "\n",
        "# img = open_image(fn); img.shape\n",
        "\n",
        "\n",
        "\n",
        "# torch.Size([3, 850, 1042])\n",
        "\n",
        "\n",
        "\n",
        "# _,img_hr,b = learn.predict(img)\n",
        "\n",
        "\n",
        "\n",
        "# show_image(img, figsize=(18,15), interpolation='nearest');\n",
        "\n",
        "\n",
        "\n",
        "# Image(img_hr).show(figsize=(18,15))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}