{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant_classification_tensorflow_keras.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiteshAI/Plant_Classification/blob/developer/plant_classification_tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QudZgXK8M6U8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6NFTamlY2vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/plant_classification/datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqVl-JzKNhOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def get_train_valid_data(batch_size, train_dir, IMG_HEIGHT, IMG_WIDTH):\n",
        "    image_gen_train = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        validation_split=0.2,\n",
        "        rotation_range=45,\n",
        "        width_shift_range=.15,\n",
        "        height_shift_range=.15,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.5\n",
        "    )\n",
        "\n",
        "    image_gen_val = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "\n",
        "    train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                         directory=train_dir,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                         class_mode='categorical',\n",
        "                                                         subset='training'\n",
        "                                                         )\n",
        "\n",
        "    label_map = (train_data_gen.class_indices)\n",
        "    print(label_map)\n",
        "\n",
        "    val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical',\n",
        "                                                     subset='validation',\n",
        "\n",
        "                                                     )\n",
        "\n",
        "    sample_training_images, _ = next(train_data_gen)\n",
        "    sample_testing_images, _ = next(val_data_gen)\n",
        "    return train_data_gen, val_data_gen\n",
        "\n",
        "\n",
        "\n",
        "def plot_acc_and_validation(history, model_name):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # If early stopping not used add epcos_range to plot graph for complete epochs\n",
        "    # epochs_range = range(epochs)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    import os\n",
        "    my_path = os.path.abspath('/content/drive/My Drive/plant_classification/plot_results')\n",
        "\n",
        "\n",
        "    my_file = model_name + 'plot.png'\n",
        "    plt.savefig(os.path.join(my_path, my_file))\n",
        "\n",
        "\n",
        "def evaluation_summary_prec_f1_score(model, val_data_gen, batch_size):\n",
        "    validation_steps_per_epoch = (val_data_gen.samples // batch_size)\n",
        "    predictions = model.predict_generator(val_data_gen, steps=validation_steps_per_epoch)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = val_data_gen.classes\n",
        "    class_labels = list(val_data_gen.class_indices.keys())\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "    print(report)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7CtRqkpM_XM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/plant_classification\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "IMG_HEIGHT = 64\n",
        "IMG_WIDTH = 64\n",
        "OUTPUT_CLASS = 52\n",
        "\n",
        "DATASET_PATH = '/content/drive/My Drive/plant_classification/datasets/plant_leaf'\n",
        "MODEL_PATH = '/content/drive/My Drive/plant_classification/final_model_plant_leaf'\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "MODEL_NAME = os.path.join(MODEL_PATH, 'model_' + str(epochs) + '.h5')\n",
        "\n",
        "\n",
        "checkpoint_path = \"training_leaf_classification/cp-{epoch:04d}.ckpt\"\n",
        "keras_callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=50, mode='auto'),\n",
        "    # TensorBoard(log_dir='/home/hitesh/Documents/THESIS/tensorflow_thesis_scripts/tensorboard_logs', histogram_freq=0,\n",
        "    #             write_graph=False),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min')\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# checkpoint_path = \"training_rice_classification/cp-{epoch:04d}.ckpt\"\n",
        "train_dir = os.path.join(DATASET_PATH, 'train')\n",
        "\n",
        "\n",
        "train_data_gen, val_data_gen = get_train_valid_data(batch_size=batch_size, train_dir=train_dir,\n",
        "                                                        IMG_HEIGHT=IMG_HEIGHT,\n",
        "                                                        IMG_WIDTH=IMG_WIDTH)\n",
        "\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(52, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional VGG16 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/plant_classification/training_leaf_classification/cp-0001.ckpt')\n",
        "\n",
        "\n",
        "model.fit_generator(\n",
        "        train_data_gen,\n",
        "        steps_per_epoch=train_data_gen.samples // batch_size,\n",
        "        initial_epoch = 2,\n",
        "        epochs=epochs,\n",
        "        callbacks=keras_callbacks,\n",
        "        validation_data=val_data_gen,\n",
        "        validation_steps=val_data_gen.samples // batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:10]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[10:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "history = model.fit_generator(\n",
        "        train_data_gen,\n",
        "        steps_per_epoch=train_data_gen.samples // batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=keras_callbacks,\n",
        "        validation_data=val_data_gen,\n",
        "        validation_steps=val_data_gen.samples // batch_size,\n",
        "\n",
        "    )\n",
        "\n",
        "plot_acc_and_validation(history, 'model_plant')\n",
        "model.save(MODEL_NAME + 'model_plant')\n",
        "model1 = tf.keras.models.load_model(MODEL_NAME + 'model_plant')\n",
        "evaluation_summary_prec_f1_score(model1, val_data_gen, batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lndyailxtVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkv-P36KkYXa",
        "colab_type": "text"
      },
      "source": [
        "For Persistent Training"
      ]
    }
  ]
}